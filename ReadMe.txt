Name 	: Shah, Harshil
CSUID 	: 830387790
(For better looking of ReadMe, open it in gedit (Keep It Maximized))

Index
-----

1. 	Included Files
2. 	How To Run
3. 	Important Notes
4. 	Class Description


1. 	Included Files
--	--------------
(a)	All Source Java Files Included Inside Packages Shown Below ( Folder CS455 )
		package cs455.harvester
(b)	Makefile
(c)	ReadMe


2.	How To Run
--	----------
Put pathToConfig file where directory cs455 has been placed.
So notation will look like this
	
....
	-cs455
	-pathToConfig
	-lib
	-Makefile
	-README

lib contains external jar file
Compile code using Makefile & run your script accordingly as mentioned in pathToConfig.
If pathToConfig shows different crawler's location than where it really is, socket exception will be thrown

3. 	Important Notes
--	---------------
(a)	Execution of ThreadPooling
	--------------------------
	Configuration of Pool
	-According to Input, threadPoolSize will be assigned :: cs455.harvester.Crawler Line: 168
	-It will be passed to ThreadPoolManager :: cs455.harvester.Crawler Line: 37
	-ThreadPoolManager will  initialize all threads  :: cs455.harvester.ThreadPoolManager Line: 32 to 45
	-All threads will wait for task to be assigned by Manager :: cs455.harvester.WorkerThread Line: 42
	-Threads will be released & make it available to Manager. :: cs455.harvester.WorkerThread Line: 88 & 92

	If niceness is 1 second, crawling of all pages can be done in nearly, 550 - 600 seconds

	
(b)	Flow of Execution
	-----------------
	Crawler instance will be created as described in Section 2 & wait for other crawlers to join the overlay by displaying "Crawler Is Online Now On PORT: 47790 HOST: $xyz..! Other Crawlers Can Send Requests" message on console.

	Crawler will wait for 10 seconds to start crawling pages as it will wait for all the connection to be set up by displaying "This Crawler Will Now Initiate Connection To Other Crawlers" message on console.
	After predefined timeout, crawler will initiate crawling. 

	If before connection is setup, one crawler receives hand off, it will add task to queue only & display "Waiting For Proper SetUp Of Connection .. Even Though Hand Of Is Given To This Crawler " message on console.

	While crawling, if crawler receives hand off, it will add task to taskList and display the status of crawler by displaying "HandOff Added | Crawler Status: $xyz" message on console.
	
	Further,  it will also shows whether all the acknowledgment for hand off to other crawlers received or not.
	
	When crawler has finished crawling, it will send completion report to all other crawlers and will stay active for other handoffs.
	
	If it has completed crawling, and receives hand off, it will send in-completion status to all other crawlers and after executing handoff, it will again send completion status to all crawlers.
	
	When completion of all the crawlers in overlay is successful, all crawlers will store data structure inside directory "/tmp/cs455-hkshah" in local computer

	Crawler will then terminate process and shows execution time

4. 	Class Description
--	-----------------
	package cs455.harvester
	--------------------------
	
	class Crawler		:	It will initialize ThreadPoolManager & also start handling messages send by other crawlers
					It will wait for 10 seconds before initializing connection to all other crawlers according to pathToConfig file.
					After that, it will start crawling page
					It will divert appropriate hand off request, acknowledgment, completion status & in-completion status to respective classes or handles them by it-self
	
	class ThreadPoolManager	:	It will initialize Threads 
					It it-self is a thread to assign task to available worker thread
					It is also responsible for handling hand off, sending completion/in-completion report.
					When all crawlers are done crawling pages, it will store data structure in the directory mentioned above.

	class TaskRegistry	:	It stores all the executed task by the crawler.

	class WorkerThread	:	It is a thread. It will be initialized by Manager & wait for task to be assigned by Manager.
					When task is assigned to respective WorkerThread, it will execute relative task's execute method to crawl assigned page.
					After completing the executing of task, WorkerThread will release it-self to ThreadPoolManager & again wait for task to be assigned.
	
	class Task		:	It is a task generated by other task or root task. It contain executeTask() method to crawl the page it is assigned. 
					executeTask() will be called only by workerThread.
					While crawling page, task will create new child task too and add newly generated tasks to taskList of ThreadPoolManager	
	
	class TCPServerThread	:	It is a thread, used for creating connection between other crawlers.
	
	class TCPConnection	:	It is useful to initialize TCPReceiverThread & TCPSender

	class TCPReceiverThread	:	It is a thread, always running, to listen incoming messages

	class TCPSender		:	It is useful to send data on given socket.

	class Protocols		:	It is declaration of all protocols used by crawler.

	class CrawlerSendHandOff:	It generates appropriate wire format for Handing off the task to other crawler

	class CrawlerGetACK	:	It generates appropriate wire format for acknowledging other crawler of successful handoff

	class CrawlerSendPositiveStatus:It generates appropriate wire format to report completion status to other crawlers

	class CrawlerSendNegativeStatus:It generates appropriate wire format to report in-completion status to other crawlers

